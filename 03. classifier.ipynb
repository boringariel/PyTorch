{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Classifying Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
    "\n",
    "#imput data shape: 8*8\n",
    "print(x_data.data.shape) # torch.Size([759, 8])\n",
    "\n",
    "#result shape: 8*1\n",
    "print(y_data.data.shape) # torch.Size([759, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6941694021224976\n",
      "1 0.6940499544143677\n",
      "2 0.6939440965652466\n",
      "3 0.6938505172729492\n",
      "4 0.6937676668167114\n",
      "5 0.6936941742897034\n",
      "6 0.6936291456222534\n",
      "7 0.6935715079307556\n",
      "8 0.6935203075408936\n",
      "9 0.6934749484062195\n",
      "10 0.6934346556663513\n",
      "11 0.6933989524841309\n",
      "12 0.6933671832084656\n",
      "13 0.6933388710021973\n",
      "14 0.6933136582374573\n",
      "15 0.6932913064956665\n",
      "16 0.6932712197303772\n",
      "17 0.6932533383369446\n",
      "18 0.6932373642921448\n",
      "19 0.6932229399681091\n",
      "20 0.6932101249694824\n",
      "21 0.693198561668396\n",
      "22 0.6931881904602051\n",
      "23 0.6931787729263306\n",
      "24 0.6931702494621277\n",
      "25 0.6931625008583069\n",
      "26 0.6931554675102234\n",
      "27 0.6931490302085876\n",
      "28 0.6931432485580444\n",
      "29 0.6931378245353699\n",
      "30 0.6931328177452087\n",
      "31 0.6931282877922058\n",
      "32 0.6931240558624268\n",
      "33 0.6931200623512268\n",
      "34 0.693116307258606\n",
      "35 0.6931129097938538\n",
      "36 0.6931096315383911\n",
      "37 0.693106472492218\n",
      "38 0.693103551864624\n",
      "39 0.6931008100509644\n",
      "40 0.6930980682373047\n",
      "41 0.6930955648422241\n",
      "42 0.6930930614471436\n",
      "43 0.6930906772613525\n",
      "44 0.6930884122848511\n",
      "45 0.6930861473083496\n",
      "46 0.6930839419364929\n",
      "47 0.693081796169281\n",
      "48 0.6930797100067139\n",
      "49 0.6930776834487915\n",
      "50 0.6930756568908691\n",
      "51 0.6930736899375916\n",
      "52 0.6930716037750244\n",
      "53 0.6930696964263916\n",
      "54 0.6930677890777588\n",
      "55 0.6930659413337708\n",
      "56 0.6930640339851379\n",
      "57 0.6930622458457947\n",
      "58 0.6930603981018066\n",
      "59 0.6930584907531738\n",
      "60 0.6930567026138306\n",
      "61 0.6930548548698425\n",
      "62 0.693053126335144\n",
      "63 0.6930512189865112\n",
      "64 0.6930494904518127\n",
      "65 0.6930477023124695\n",
      "66 0.6930458545684814\n",
      "67 0.693044126033783\n",
      "68 0.6930422782897949\n",
      "69 0.6930405497550964\n",
      "70 0.693038821220398\n",
      "71 0.6930369734764099\n",
      "72 0.6930351257324219\n",
      "73 0.6930333971977234\n",
      "74 0.6930316090583801\n",
      "75 0.6930298805236816\n",
      "76 0.6930281519889832\n",
      "77 0.6930263638496399\n",
      "78 0.6930246353149414\n",
      "79 0.6930228471755981\n",
      "80 0.6930211186408997\n",
      "81 0.6930192708969116\n",
      "82 0.6930176019668579\n",
      "83 0.6930157542228699\n",
      "84 0.6930140256881714\n",
      "85 0.6930122971534729\n",
      "86 0.6930105686187744\n",
      "87 0.6930087804794312\n",
      "88 0.6930070519447327\n",
      "89 0.6930052638053894\n",
      "90 0.6930035352706909\n",
      "91 0.6930017471313477\n",
      "92 0.6929999589920044\n",
      "93 0.6929981708526611\n",
      "94 0.6929965019226074\n",
      "95 0.6929947137832642\n",
      "96 0.6929929256439209\n",
      "97 0.6929911375045776\n",
      "98 0.6929894089698792\n",
      "99 0.6929876208305359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bioinfo205_01\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "model = Model()\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Note. Titanic dataset Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "raw = pd.read_csv('./train.csv')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "raw = pd.read_csv('./train.csv')\n",
    "\n",
    "#preprocess\n",
    "\n",
    "#raw: training data\n",
    "raw = raw.iloc[:,[2, 4, 5, 6, 7, 9, -1]]\n",
    "raw['Age'] = raw['Age'].fillna(raw['Age'].mean())\n",
    "raw['Embarked'] = raw['Embarked'].fillna('unknown')\n",
    "\n",
    "#encording\n",
    "#sex: male=1, female=2\n",
    "#embarked: C=0, Q=1, S=2, unknown=3\n",
    "for col in range(raw.shape[1]):\n",
    "    raw.iloc[:,col] = LabelEncoder().fit_transform(raw.iloc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv('./train_p.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "class TitanicDataset(Dataset):\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('train_p.csv', delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:])\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dataset = TitanicDataset()\n",
    "train_loader = DataLoader(dataset = dataset, batch_size = 32, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(6, 3)\n",
    "        self.l2 = torch.nn.Linear(3, 2)\n",
    "        self.l3 = torch.nn.Linear(2, 1)\n",
    "\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(0.6740)\n",
      "0 1 tensor(0.5924)\n",
      "0 2 tensor(0.5732)\n",
      "0 3 tensor(0.4511)\n",
      "0 4 tensor(0.4555)\n",
      "0 5 tensor(0.2856)\n",
      "0 6 tensor(0.1101)\n",
      "0 7 tensor(0.2092)\n",
      "0 8 tensor(0.3540)\n",
      "0 9 tensor(0.0295)\n",
      "0 10 tensor(0.0191)\n",
      "0 11 tensor(-0.1912)\n",
      "0 12 tensor(0.1454)\n",
      "0 13 tensor(-0.3460)\n",
      "0 14 tensor(-0.1108)\n",
      "0 15 tensor(-0.3569)\n",
      "0 16 tensor(-0.4172)\n",
      "0 17 tensor(0.0041)\n",
      "0 18 tensor(-0.6998)\n",
      "0 19 tensor(-0.2007)\n",
      "0 20 tensor(-0.5498)\n",
      "0 21 tensor(-0.3682)\n",
      "0 22 tensor(-0.3959)\n",
      "0 23 tensor(-0.7920)\n",
      "0 24 tensor(-0.5262)\n",
      "0 25 tensor(0.2453)\n",
      "0 26 tensor(-0.6932)\n",
      "0 27 tensor(0.1029)\n",
      "1 0 tensor(-0.5997)\n",
      "1 1 tensor(-0.1224)\n",
      "1 2 tensor(-0.8610)\n",
      "1 3 tensor(-0.7518)\n",
      "1 4 tensor(-0.7045)\n",
      "1 5 tensor(-0.9743)\n",
      "1 6 tensor(-1.2668)\n",
      "1 7 tensor(-0.7198)\n",
      "1 8 tensor(-1.2745)\n",
      "1 9 tensor(-1.0529)\n",
      "1 10 tensor(-1.5612)\n",
      "1 11 tensor(-1.2340)\n",
      "1 12 tensor(-0.9732)\n",
      "1 13 tensor(-0.1705)\n",
      "1 14 tensor(-0.7939)\n",
      "1 15 tensor(-0.8149)\n",
      "1 16 tensor(-0.7242)\n",
      "1 17 tensor(-1.0668)\n",
      "1 18 tensor(-0.8683)\n",
      "1 19 tensor(-0.4296)\n",
      "1 20 tensor(-1.1247)\n",
      "1 21 tensor(-1.5023)\n",
      "1 22 tensor(-1.7856)\n",
      "1 23 tensor(-0.9737)\n",
      "1 24 tensor(-0.9902)\n",
      "1 25 tensor(-0.2400)\n",
      "1 26 tensor(-1.6553)\n",
      "1 27 tensor(-1.0787)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(2):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.data)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
